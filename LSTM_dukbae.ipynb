{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c99f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipaddress\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a57e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ip2int(ip):\n",
    "    try:\n",
    "        return int(ipaddress.ip_address(ip))\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "def preprocess_sequence_data(df, time_window='1T', time_steps=10):\n",
    "    df.columns = df.columns.str.replace('[ /]', '_', regex=True)\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    df.dropna(subset=['Timestamp'], inplace=True)\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
    "    df['Source_IP'] = df['Source_IP'].astype(str).apply(convert_ip2int)\n",
    "    df['Destination_IP'] = df['Destination_IP'].astype(str).apply(convert_ip2int)\n",
    "    \n",
    "    df.drop(columns=['Flow_ID'], inplace=True, errors='ignore')\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    df.set_index('Timestamp', inplace=True)\n",
    "    df['Label'] = np.where(df['Label'] == 'BENIGN', 0, 1)\n",
    "\n",
    "    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "    agg_funcs = {col: 'mean' for col in numeric_cols if col not in ['Label']}\n",
    "    agg_funcs.update({'Label': 'max'})\n",
    "    special_aggs = {\n",
    "        'Total_Fwd_Packets': 'sum', 'Total_Backward_Packets': 'sum',\n",
    "        'Total_Length_of_Fwd_Packets': 'sum', 'Source_IP': 'nunique', 'Destination_IP': 'nunique'\n",
    "    }\n",
    "    for col, func in special_aggs.items():\n",
    "        if col in df.columns:\n",
    "            agg_funcs[col] = func\n",
    "    agg_funcs = {k: v for k, v in agg_funcs.items() if k in df.columns}\n",
    "\n",
    "    df_agg = df.resample(time_window).agg(agg_funcs)\n",
    "    df_agg.fillna(0, inplace=True)\n",
    "    \n",
    "    X_agg = df_agg.drop('Label', axis=1).values\n",
    "    y_agg = df_agg['Label'].values\n",
    "    \n",
    "    X_seq, y_seq = [], []\n",
    "    if len(X_agg) > time_steps:\n",
    "        for i in range(len(X_agg) - time_steps):\n",
    "            X_seq.append(X_agg[i:(i + time_steps)])\n",
    "            y_seq.append(y_agg[i + time_steps])\n",
    "\n",
    "    return np.array(X_seq), np.array(y_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8d1d821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bell1\\AppData\\Local\\Temp\\ipykernel_10748\\4145867794.py:84: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_agg = df.resample(time_window).agg(agg_funcs)\n",
      "C:\\Users\\bell1\\AppData\\Local\\Temp\\ipykernel_10748\\4145867794.py:84: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_agg = df.resample(time_window).agg(agg_funcs)\n",
      "C:\\Users\\bell1\\AppData\\Local\\Temp\\ipykernel_10748\\4145867794.py:84: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_agg = df.resample(time_window).agg(agg_funcs)\n",
      "C:\\Users\\bell1\\AppData\\Local\\Temp\\ipykernel_10748\\4145867794.py:84: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_agg = df.resample(time_window).agg(agg_funcs)\n",
      "C:\\Users\\bell1\\AppData\\Local\\Temp\\ipykernel_10748\\4145867794.py:84: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_agg = df.resample(time_window).agg(agg_funcs)\n",
      "C:\\Users\\bell1\\AppData\\Local\\Temp\\ipykernel_10748\\4145867794.py:84: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_agg = df.resample(time_window).agg(agg_funcs)\n",
      "C:\\Users\\bell1\\AppData\\Local\\Temp\\ipykernel_10748\\4145867794.py:84: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_agg = df.resample(time_window).agg(agg_funcs)\n",
      "C:\\Users\\bell1\\AppData\\Local\\Temp\\ipykernel_10748\\4145867794.py:84: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_agg = df.resample(time_window).agg(agg_funcs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[31mTypeError\u001b[39m: only length-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m nsamples, nsteps, nfeatures = X_train_seq.shape\n\u001b[32m     37\u001b[39m X_train_2d = X_train_seq.reshape((nsamples * nsteps, nfeatures))\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m X_train_scaled_2d = \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m X_train_scaled_seq = X_train_scaled_2d.reshape((nsamples, nsteps, nfeatures))\n\u001b[32m     41\u001b[39m nsamples_test, nsteps_test, nfeatures_test = X_test_seq.shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\UGRP_prac\\venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\UGRP_prac\\venv\\Lib\\site-packages\\sklearn\\base.py:918\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    903\u001b[39m         warnings.warn(\n\u001b[32m    904\u001b[39m             (\n\u001b[32m    905\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    914\u001b[39m         )\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\UGRP_prac\\venv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:894\u001b[39m, in \u001b[36mStandardScaler.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    892\u001b[39m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    893\u001b[39m \u001b[38;5;28mself\u001b[39m._reset()\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\UGRP_prac\\venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\UGRP_prac\\venv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:930\u001b[39m, in \u001b[36mStandardScaler.partial_fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    898\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[32m    899\u001b[39m \n\u001b[32m    900\u001b[39m \u001b[33;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    927\u001b[39m \u001b[33;03m    Fitted scaler.\u001b[39;00m\n\u001b[32m    928\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    929\u001b[39m first_call = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mn_samples_seen_\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    938\u001b[39m n_features = X.shape[\u001b[32m1\u001b[39m]\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\UGRP_prac\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2942\u001b[39m         out = X, y\n\u001b[32m   2943\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2945\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\UGRP_prac\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1055\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1053\u001b[39m         array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1054\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1055\u001b[39m         array = \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1057\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1058\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.format(array)\n\u001b[32m   1059\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\UGRP_prac\\venv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:839\u001b[39m, in \u001b[36m_asarray_with_order\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    837\u001b[39m     array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    838\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m     array = \u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xp.asarray(array)\n",
      "\u001b[31mValueError\u001b[39m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "data_path = 'dataset/'\n",
    "all_files = [f for f in os.listdir(data_path) if f.endswith('.csv')]\n",
    "train_files = [f for f in all_files if 'Wednesday' not in f]\n",
    "test_files = [f for f in all_files if 'Wednesday' in f]\n",
    "\n",
    "TIME_STEPS = 10\n",
    "TIME_WINDOW = '1T'\n",
    "\n",
    "X_train_list, y_train_list = [], []\n",
    "for file_name in train_files:\n",
    "    file_path = os.path.join(data_path, file_name)\n",
    "    df = pd.read_csv(file_path, encoding='latin1', low_memory=False, on_bad_lines='skip')\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    X_temp, y_temp = preprocess_sequence_data(df, time_window=TIME_WINDOW, time_steps=TIME_STEPS)\n",
    "    X_train_list.append(X_temp)\n",
    "    y_train_list.append(y_temp)\n",
    "\n",
    "X_test_list, y_test_list = [], []\n",
    "for file_name in test_files:\n",
    "    file_path = os.path.join(data_path, file_name)\n",
    "    df = pd.read_csv(file_path, encoding='latin1', low_memory=False, on_bad_lines='skip')\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    X_temp, y_temp = preprocess_sequence_data(df, time_window=TIME_WINDOW, time_steps=TIME_STEPS)\n",
    "    X_test_list.append(X_temp)\n",
    "    y_test_list.append(y_temp)\n",
    "\n",
    "X_train_seq = np.concatenate(X_train_list, axis=0)\n",
    "y_train_seq = np.concatenate(y_train_list, axis=0)\n",
    "X_test_seq = np.concatenate(X_test_list, axis=0)\n",
    "y_test_seq = np.concatenate(y_test_list, axis=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "nsamples, nsteps, nfeatures = X_train_seq.shape\n",
    "X_train_2d = X_train_seq.reshape((nsamples * nsteps, nfeatures))\n",
    "X_train_scaled_2d = scaler.fit_transform(X_train_2d)\n",
    "X_train_scaled_seq = X_train_scaled_2d.reshape((nsamples, nsteps, nfeatures))\n",
    "\n",
    "nsamples_test, nsteps_test, nfeatures_test = X_test_seq.shape\n",
    "X_test_2d = X_test_seq.reshape((nsamples_test * nsteps_test, nfeatures_test))\n",
    "X_test_scaled_2d = scaler.transform(X_test_2d)\n",
    "X_test_scaled_seq = X_test_scaled_2d.reshape((nsamples_test, nsteps_test, nfeatures_test))\n",
    "\n",
    "print(f\"학습 데이터 형태: {X_train_seq.shape}, {y_train_seq.shape}\")\n",
    "print(f\"테스트 데이터 형태: {X_test_seq.shape}, {y_test_seq.shape}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2ad81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 가중치: {0: np.float64(0.6132075471698113), 1: np.float64(2.7083333333333335)}\n"
     ]
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train_seq),\n",
    "    y=y_train_seq\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(f\"클래스 가중치: {class_weights_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae698297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM 모델 학습 시작...\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\projects\\UGRP_prac\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5911 - loss: 0.5870\n",
      "Epoch 2/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8574 - loss: 0.3400\n",
      "Epoch 3/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9035 - loss: 0.2191\n",
      "Epoch 4/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9118 - loss: 0.2000\n",
      "Epoch 5/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9444 - loss: 0.1619\n",
      "Epoch 6/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9446 - loss: 0.1446\n",
      "Epoch 7/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9591 - loss: 0.1004\n",
      "Epoch 8/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9507 - loss: 0.1202\n",
      "Epoch 9/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9544 - loss: 0.1073\n",
      "Epoch 10/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9458 - loss: 0.1060\n",
      "Epoch 11/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9509 - loss: 0.1130\n",
      "Epoch 12/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9636 - loss: 0.0846\n",
      "Epoch 13/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9567 - loss: 0.0949\n",
      "Epoch 14/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9697 - loss: 0.0751\n",
      "Epoch 15/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9716 - loss: 0.0635\n",
      "Epoch 16/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9728 - loss: 0.0601\n",
      "Epoch 17/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9599 - loss: 0.0817\n",
      "Epoch 18/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9707 - loss: 0.0619\n",
      "Epoch 19/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9807 - loss: 0.0461\n",
      "Epoch 20/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9726 - loss: 0.0632\n",
      "Epoch 21/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9680 - loss: 0.0648\n",
      "Epoch 22/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9782 - loss: 0.0501\n",
      "Epoch 23/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9715 - loss: 0.0660\n",
      "Epoch 24/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9761 - loss: 0.0550\n",
      "Epoch 25/25\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9771 - loss: 0.0364\n",
      "LSTM 모델 학습 완료.\n"
     ]
    }
   ],
   "source": [
    "## LSTM\n",
    "def create_lstm_model(input_shape, lstm_units=100, dense_units=50, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential([\n",
    "        LSTM(lstm_units, activation='tanh', input_shape=input_shape),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(dense_units, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "print(\"LSTM 모델 학습 시작...\")\n",
    "LSTM_starttime = time.time()\n",
    "\n",
    "input_shape = (X_train_scaled_seq.shape[1], X_train_scaled_seq.shape[2])\n",
    "\n",
    "lstm_model = create_lstm_model(input_shape=input_shape)\n",
    "\n",
    "history = lstm_model.fit(\n",
    "    X_train_scaled_seq,\n",
    "    y_train_seq,\n",
    "    epochs=25,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    class_weight=class_weights_dict\n",
    ")\n",
    "LSTM_endtime = time.time()\n",
    "LSTM_time = LSTM_endtime - LSTM_starttime\n",
    "print(\"LSTM 모델 학습 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b88c758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      "Evaluating model performance on the Test set...\n",
      "\n",
      "--- LSTM Results---\n",
      "Accuracy: 0.8408\n",
      "Recall:   0.2907\n",
      "F1-Score: 0.3067\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  BENIGN (0)       0.90      0.92      0.91       624\n",
      "  ATTACK (1)       0.32      0.29      0.31        86\n",
      "\n",
      "    accuracy                           0.84       710\n",
      "   macro avg       0.61      0.60      0.61       710\n",
      "weighted avg       0.83      0.84      0.84       710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_lstm_prob = lstm_model.predict(X_test_scaled_seq).flatten()\n",
    "y_pred_lstm = (y_pred_lstm_prob > 0.5).astype(int)\n",
    "accuracy_lstm = accuracy_score(y_test_seq, y_pred_lstm)\n",
    "recall_lstm = recall_score(y_test_seq, y_pred_lstm)\n",
    "f1_lstm = f1_score(y_test_seq, y_pred_lstm)\n",
    "report = classification_report(y_test_seq, y_pred_lstm, target_names=['BENIGN (0)', 'ATTACK (1)'])\n",
    "\n",
    "print(\"\\nEvaluating model performance on the Test set...\")\n",
    "# Predict on the separate test set\n",
    "print(f\"\\n--- LSTM Results---\")\n",
    "print(f\"Accuracy: {accuracy_lstm:.4f}\")\n",
    "print(f\"Recall:   {recall_lstm:.4f}\")\n",
    "print(f\"F1-Score: {f1_lstm:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
