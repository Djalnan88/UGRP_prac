{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import ipaddress\n",
    "import scikeras\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "\n",
    "train_dataset_path = 'dataset/Wednesday-workingHours.pcap_ISCX.csv'\n",
    "test_dataset_path = 'dataset/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_dataset_path)\n",
    "test_data = pd.read_csv(test_dataset_path)\n",
    "\n",
    "def convert_ip2int(ip):\n",
    "    try:\n",
    "        return int(ipaddress.ip_address(ip))\n",
    "    except ValueError:\n",
    "        return 0  # Return 0 for invalid IP addresses    \n",
    "\n",
    "def preprocess_data(data):\n",
    "    df = data.copy()\n",
    "    df.columns = df.columns.str.strip().str.replace('[ /]', '_', regex=True)\n",
    "    \n",
    "    df['Source_IP'] = df['Source_IP'].apply(convert_ip2int)\n",
    "    df['Destination_IP'] = df['Destination_IP'].apply(convert_ip2int)\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce').astype(np.int64)\n",
    "\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    y = np.where(df['Label'] == 'BENIGN', 0, 1)\n",
    "    X = df.drop('Label', axis=1)\n",
    "    X = X.select_dtypes(include=np.number)\n",
    "    return X, y\n",
    "# 위의 과정을 통해 Flow ID라는 int 형태가 될 수 없는 데이터와\n",
    "# y로 분리되어 있는 Label을 제외한 나머지 데이터는 모두 숫자형으로 변환된다.\n",
    "\n",
    "X_train, y_train = preprocess_data(train_data)\n",
    "X_test, y_test = preprocess_data(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ac70e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Top 6 Features:\n",
      " - Source_IP\n",
      " - Bwd_Packet_Length_Mean\n",
      " - Avg_Bwd_Segment_Size\n",
      " - Timestamp\n",
      " - Bwd_Packet_Length_Std\n",
      " - Destination_Port\n",
      "## Best Features (Top 67):\n",
      " - Source_IP\n",
      " - Source_Port\n",
      " - Destination_IP\n",
      " - Destination_Port\n",
      " - Protocol\n",
      " - Timestamp\n",
      " - Flow_Duration\n",
      " - Total_Fwd_Packets\n",
      " - Total_Backward_Packets\n",
      " - Total_Length_of_Fwd_Packets\n",
      " - Total_Length_of_Bwd_Packets\n",
      " - Fwd_Packet_Length_Max\n",
      " - Fwd_Packet_Length_Min\n",
      " - Fwd_Packet_Length_Mean\n",
      " - Fwd_Packet_Length_Std\n",
      " - Bwd_Packet_Length_Max\n",
      " - Bwd_Packet_Length_Min\n",
      " - Bwd_Packet_Length_Mean\n",
      " - Bwd_Packet_Length_Std\n",
      " - Flow_Bytes_s\n",
      " - Flow_Packets_s\n",
      " - Flow_IAT_Mean\n",
      " - Flow_IAT_Std\n",
      " - Flow_IAT_Max\n",
      " - Flow_IAT_Min\n",
      " - Fwd_IAT_Total\n",
      " - Fwd_IAT_Mean\n",
      " - Fwd_IAT_Std\n",
      " - Fwd_IAT_Max\n",
      " - Fwd_IAT_Min\n",
      " - Bwd_IAT_Mean\n",
      " - Bwd_IAT_Std\n",
      " - Bwd_IAT_Max\n",
      " - Bwd_IAT_Min\n",
      " - Fwd_Header_Length\n",
      " - Bwd_Header_Length\n",
      " - Fwd_Packets_s\n",
      " - Bwd_Packets_s\n",
      " - Min_Packet_Length\n",
      " - Max_Packet_Length\n",
      " - Packet_Length_Mean\n",
      " - Packet_Length_Std\n",
      " - Packet_Length_Variance\n",
      " - FIN_Flag_Count\n",
      " - PSH_Flag_Count\n",
      " - ACK_Flag_Count\n",
      " - URG_Flag_Count\n",
      " - Down_Up_Ratio\n",
      " - Average_Packet_Size\n",
      " - Avg_Fwd_Segment_Size\n",
      " - Avg_Bwd_Segment_Size\n",
      " - Fwd_Header_Length.1\n",
      " - Subflow_Fwd_Packets\n",
      " - Subflow_Fwd_Bytes\n",
      " - Subflow_Bwd_Packets\n",
      " - Subflow_Bwd_Bytes\n",
      " - Init_Win_bytes_forward\n",
      " - Init_Win_bytes_backward\n",
      " - act_data_pkt_fwd\n",
      " - min_seg_size_forward\n",
      " - Active_Mean\n",
      " - Active_Std\n",
      " - Active_Max\n",
      " - Active_Min\n",
      " - Idle_Mean\n",
      " - Idle_Std\n",
      " - Idle_Max\n"
     ]
    }
   ],
   "source": [
    "top6_features_path = open('models/top6_features.txt', 'r')\n",
    "top6_features = [line.strip() for line in top6_features_path.readlines()]\n",
    "top6_features_path.close()\n",
    "print(\"## Top 6 Features:\")\n",
    "for feature in top6_features:\n",
    "    print(f\" - {feature}\")\n",
    "\n",
    "best_features_path = open('models/best_features.txt', 'r')\n",
    "best_features = [line.strip() for line in best_features_path.readlines()]\n",
    "best_features_path.close()\n",
    "print(f\"## Best Features (Top {len(best_features)}):\")\n",
    "for feature in best_features:\n",
    "    print(f\" - {feature}\")\n",
    "\n",
    "X_train_top6 = X_train[top6_features]\n",
    "X_test_top6 = X_test[top6_features]\n",
    "\n",
    "X_train_best = X_train[best_features]\n",
    "X_test_best = X_test[best_features]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_lstm = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "X_test_lstm = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 모델 불러오기\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\csp\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.7.0 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy._core'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m rf_best_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/rf_model_best.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m lstm_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/lstm_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m rf_full_model \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrf_full_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m rf_top6_model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(rf_top6_path)\n\u001b[0;32m     31\u001b[0m rf_best_model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(rf_best_path)\n",
      "File \u001b[1;32mc:\\Users\\csp\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[0;32m    656\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[1;32m--> 658\u001b[0m             obj \u001b[38;5;241m=\u001b[39m \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\csp\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    575\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[0;32m    579\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[0;32m    583\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\csp\\AppData\\Local\\Programs\\Python\\Python38\\lib\\pickle.py:1212\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1210\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1212\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[0;32m   1214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32mc:\\Users\\csp\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\numpy_pickle.py:415\u001b[0m, in \u001b[0;36mNumpyUnpickler.load_build\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(array_wrapper, NDArrayWrapper):\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompat_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack\u001b[38;5;241m.\u001b[39mappend(\u001b[43marray_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\csp\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\numpy_pickle.py:252\u001b[0m, in \u001b[0;36mNumpyArrayWrapper.read\u001b[1;34m(self, unpickler)\u001b[0m\n\u001b[0;32m    250\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_mmap(unpickler)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 252\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43munpickler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;66;03m# Manage array subclass case\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(array, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__array_prepare__\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubclass \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (unpickler\u001b[38;5;241m.\u001b[39mnp\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m    257\u001b[0m                           unpickler\u001b[38;5;241m.\u001b[39mnp\u001b[38;5;241m.\u001b[39mmemmap)):\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;66;03m# We need to reconstruct another subclass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\csp\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\numpy_pickle.py:152\u001b[0m, in \u001b[0;36mNumpyArrayWrapper.read_array\u001b[1;34m(self, unpickler)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# Now read the actual data.\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mhasobject:\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;66;03m# The array contained Python objects. We need to unpickle the data.\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_handle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     numpy_array_alignment_bytes \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msafe_get_numpy_array_alignment_bytes()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy._core'"
     ]
    }
   ],
   "source": [
    "print(\"## 모델 불러오기\")\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "\n",
    "def create_lstm_model(lstm_units=100, dense_units=50, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential([\n",
    "        LSTM(lstm_units, activation='relu',\n",
    "        input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(dense_units, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "rf_full_path = os.path.abspath('models/rf_model_full.pkl')\n",
    "rf_top6_path = os.path.abspath('models/rf_model_top6.pkl')\n",
    "rf_best_path = os.path.abspath('models/rf_model_best.pkl')\n",
    "lstm_path = os.path.abspath('models/lstm_model.h5')\n",
    "\n",
    "rf_full_model = joblib.load(rf_full_path)\n",
    "rf_top6_model = joblib.load(rf_top6_path)\n",
    "rf_best_model = joblib.load(rf_best_path)\n",
    "\n",
    "# with h5py.File(lstm_path, 'r') as f:\n",
    "lstm_model = load_model(lstm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_full_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_curve, auc\n\u001b[1;32m----> 5\u001b[0m y_pred_rf_full \u001b[38;5;241m=\u001b[39m \u001b[43mrf_full_model\u001b[49m\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      6\u001b[0m y_pred_rf_top6 \u001b[38;5;241m=\u001b[39m rf_top6_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test_top6)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      7\u001b[0m y_pred_rf_best \u001b[38;5;241m=\u001b[39m rf_best_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test_best)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf_full_model' is not defined"
     ]
    }
   ],
   "source": [
    "## ROC 곡선 시각화\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_pred_rf_full = rf_full_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_rf_top6 = rf_top6_model.predict_proba(X_test_top6)[:, 1]\n",
    "y_pred_rf_best = rf_best_model.predict_proba(X_test_best)[:, 1]\n",
    "y_pred_lstm = lstm_model.predict(X_test_lstm).ravel()\n",
    "\n",
    "fpr_rf_full, tpr_rf_full, _ = roc_curve(y_test, y_pred_rf_full)\n",
    "fpr_rf_top6, tpr_rf_top6, _ = roc_curve(y_test, y_pred_rf_top6)\n",
    "fpr_rf_best, tpr_rf_best, _ = roc_curve(y_test, y_pred_rf_best)\n",
    "fpr_lstm, tpr_lstm, _ = roc_curve(y_test, y_pred_lstm)\n",
    "\n",
    "roc_auc_rf_full = auc(fpr_rf_full, tpr_rf_full)\n",
    "roc_auc_rf_top6 = auc(fpr_rf_top6, tpr_rf_top6)\n",
    "roc_auc_rf_best = auc(fpr_rf_best, tpr_rf_best)\n",
    "roc_auc_lstm = auc(fpr_lstm, tpr_lstm)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr_rf_full, tpr_rf_full, color='blue', label=f'RF Full Features (AUC = {roc_auc_rf_full:.4f})')\n",
    "plt.plot(fpr_rf_top6, tpr_rf_top6, color='orange', label=f'RF Top 6 Features (AUC = {roc_auc_rf_top6:.4f})')\n",
    "plt.plot(fpr_rf_best, tpr_rf_best, color='green', label=f'RF Best Features (AUC = {roc_auc_rf_best:.4f})')\n",
    "plt.plot(fpr_lstm, tpr_lstm, color='red', label=f'LSTM (AUC = {roc_auc_lstm:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='grey', linestyle='--', label='Random Guessing')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('roc_curve_comparison.png')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
